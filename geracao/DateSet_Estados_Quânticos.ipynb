{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDPB-Pe0Mr8m"
      },
      "source": [
        "#Criação do dateset de estados quânticos preparados por método\n",
        "\n",
        "Este repositório foi feito durante no Pesquisa do Trabalho de Conclusão de Curso referente a Graduação de Sistema de Informação, o artigo se encontra neste link:\n",
        "\n",
        "Estados utilizados: Uniforme Denso, Uniforme Esparso (25%, 50%,75%), Não-Uniforme Denso, Não-Uniforme Esparso (25%, 50%,75%);\n",
        "\n",
        "Métodos utilizados: Low Rank,  Dcsp, Bdsp, SVD, UCG, Isometry e Multiplexor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M2Pw3U8BSIO_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U qiskit\n",
        "!pip install -U qiskit-aer\n",
        "!pip install qclib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k2b4baKeJBHm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rnd, random\n",
        "import string\n",
        "from qiskit import QuantumCircuit, QuantumRegister, transpile\n",
        "from qiskit_aer import AerSimulator\n",
        "from qclib.state_preparation import (\n",
        "    LowRankInitialize,\n",
        "    DcspInitialize,\n",
        "    BdspInitialize,\n",
        "    SVDInitialize,\n",
        "    UCGInitialize)\n",
        "\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HLTTj9QPHsT"
      },
      "source": [
        "##Funções do controle do Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qimn_6lsHPsa"
      },
      "outputs": [],
      "source": [
        "cabecalho = ['Identifier','State', 'Qubit', 'Uniform State', 'Dense State', 'Sparsity','Duration','Output Qubit','Output CNot Gate','Output Width', 'Output Depth', 'Preparation Method']\n",
        "\n",
        "df = pd.DataFrame(columns=cabecalho)\n",
        "\n",
        "df.head()\n",
        "\n",
        "data = {\n",
        "    'Identifier': [],\n",
        "    'State': [],\n",
        "    'Qubit': [],\n",
        "    'Uniform State': [],\n",
        "    'Dense State': [],\n",
        "    'Sparsity': [],\n",
        "    'Duration': [],\n",
        "    'Output Qubit': [],\n",
        "    'Output CNot Gate': [],\n",
        "    'Output Depth': [],\n",
        "    'Output Width': [],\n",
        "    'Preparation Method': []\n",
        "}\n",
        "\n",
        "def restartData(data): #Essa reseta/limapa do dicionario\n",
        "  data = {\n",
        "      'Identifier': [],\n",
        "      'State': [],\n",
        "      'Qubit': [],\n",
        "      'Uniform State': [],\n",
        "      'Dense State': [],\n",
        "      'Sparsity': [],\n",
        "      'Duration': [],\n",
        "      'Output Qubit': [],\n",
        "      'Output CNot Gate': [],\n",
        "      'Output Depth': [],\n",
        "      'Output Width': [],\n",
        "      'Preparation Method': []\n",
        "    }\n",
        "  return data\n",
        "\n",
        "def updateData(id,data, state, num_qubits, uniform, dense, sparsity, duration, op_qubit, op_cnot, op_depth, op_width, preparation_method): #Essa funcao atualiza o dicionario com novos dados\n",
        "    novos_dados = {\n",
        "        'Identifier': id,\n",
        "        'State': state,\n",
        "        'Qubit': num_qubits,\n",
        "        'Uniform State': int(uniform),\n",
        "        'Dense State': int(dense),\n",
        "        'Sparsity': sparsity,\n",
        "        'Duration': duration,\n",
        "        'Output Qubit': op_qubit,\n",
        "        'Output CNot Gate': op_cnot,\n",
        "        'Output Depth': op_depth,\n",
        "        'Output Width': op_width,\n",
        "        'Preparation Method': preparation_method\n",
        "    }\n",
        "\n",
        "    for chave, valor in novos_dados.items():\n",
        "        data[chave].append(valor)\n",
        "    return data\n",
        "\n",
        "def addDF(data): #Essa funcao adiciona as caracteristicas do estado + duracao + o resultado dado o método em um tabela/dataframe\n",
        "    global df\n",
        "    new_data = data\n",
        "    df = pd.concat([df, pd.DataFrame(new_data)], ignore_index=False)\n",
        "    return df\n",
        "\n",
        "\n",
        "def getDuration(before_time, after_time):\n",
        "    duration = after_time - before_time\n",
        "    microseconds = duration.total_seconds() * 1000000\n",
        "    return microseconds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "argGIFIrPbnj"
      },
      "source": [
        "##Geração dos Estados Quânticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EHUjuINkpY8m"
      },
      "outputs": [],
      "source": [
        "def denseUniformState(num_qubits):\n",
        "  state_vector= np.ones(2 ** num_qubits)\n",
        "  state_vector = state_vector/np.linalg.norm(state_vector)\n",
        "  uniform = True\n",
        "  dense = True\n",
        "\n",
        "  return [state_vector, num_qubits,uniform, dense, 0]\n",
        "\n",
        "def sparseUniformState(num_qubits, sparsity):\n",
        "  s = int((sparsity)*num_qubits**2)\n",
        "  intindex=[]\n",
        "  for i in range(num_qubits**2-1):\n",
        "    intindex.append(i)\n",
        "  zero_index =rnd.sample(intindex,s)\n",
        "  state_vector = np.ones(2 ** num_qubits)\n",
        "  for i in zero_index:\n",
        "    state_vector[i]=0.\n",
        "  state_vector = state_vector/np.linalg.norm(state_vector)\n",
        "  uniform = True\n",
        "  dense = False\n",
        "  return [state_vector,num_qubits, uniform, dense, sparsity]\n",
        "\n",
        "def denseNonUniformState(num_qubits):\n",
        "  state_vector= np.random.rand(2 ** num_qubits)\n",
        "  state_vector = state_vector/np.linalg.norm(state_vector)\n",
        "  uniform = False\n",
        "  dense = True\n",
        "  return [state_vector,num_qubits, uniform, dense, 0]\n",
        "\n",
        "def sparseNonUniformState(num_qubits, sparsity):\n",
        "  s = int((sparsity)*num_qubits**2)\n",
        "  intindex=[]\n",
        "  for i in range(num_qubits**2-1):\n",
        "    intindex.append(i)\n",
        "  zero_index =rnd.sample(intindex,s)\n",
        "  state_vector= np.random.rand(2 ** num_qubits)\n",
        "  for i in zero_index:\n",
        "    state_vector[i]=0.\n",
        "  state_vector = state_vector/np.linalg.norm(state_vector)\n",
        "  uniform = False\n",
        "  dense = False\n",
        "  return [state_vector,num_qubits, uniform, dense, sparsity]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqKyzKHVPhiY"
      },
      "source": [
        "##Funções dos métodos de preparação de estados quânticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XO3T1b3ERBdb"
      },
      "outputs": [],
      "source": [
        "def lowrank(l,id):\n",
        "  global data\n",
        "  v = l[0]\n",
        "  c = QuantumCircuit(l[1])\n",
        "  before_time = datetime.now()\n",
        "  LowRankInitialize.initialize(c, v)\n",
        "  transpiled = transpile(c, basis_gates=['u', 'cx'], optimization_level=0)\n",
        "  after_time = datetime.now()\n",
        "  duration = getDuration(before_time, after_time)\n",
        "\n",
        "  op_qubit = len(transpiled.qubits)\n",
        "  op_depth = transpiled.depth()\n",
        "  op_width = transpiled.width()\n",
        "  op_cnot = transpiled.count_ops().get('cx', 0)\n",
        "  preparation_method  = 'Low Rank'\n",
        "\n",
        "  updateData(id=id,data=data, state=v, num_qubits=l[1], uniform=l[2], dense=l[3], sparsity=l[4],duration=duration,op_qubit=op_qubit, op_cnot=op_cnot, op_depth=op_depth, op_width=op_width, preparation_method=preparation_method)\n",
        "\n",
        "def svd(l,id):\n",
        "  global data\n",
        "  v = l[0]\n",
        "  c = QuantumCircuit(l[1])\n",
        "  before_time = datetime.now()\n",
        "  SVDInitialize.initialize(c, v)\n",
        "  transpiled = transpile(c, basis_gates=['u', 'cx'], optimization_level=0)\n",
        "  after_time = datetime.now()\n",
        "  duration = getDuration(before_time, after_time)\n",
        "\n",
        "  op_qubit = len(transpiled.qubits)\n",
        "  op_depth = transpiled.depth()\n",
        "  op_width = transpiled.width()\n",
        "  op_cnot = transpiled.count_ops().get('cx', 0)\n",
        "  preparation_method  = 'SVD'\n",
        "\n",
        "  updateData(id=id,data=data, state=v, num_qubits=l[1], uniform=l[2], dense=l[3], sparsity=l[4],duration=duration,op_qubit=op_qubit, op_cnot=op_cnot, op_depth=op_depth, op_width=op_width, preparation_method=preparation_method)\n",
        "\n",
        "def ucg(l,id):\n",
        "  global data\n",
        "  v = l[0]\n",
        "  c = QuantumCircuit(l[1])\n",
        "  before_time = datetime.now()\n",
        "  UCGInitialize.initialize(c, v)\n",
        "  transpiled = transpile(c, basis_gates=['u', 'cx'], optimization_level=0)\n",
        "  after_time = datetime.now()\n",
        "  duration = getDuration(before_time, after_time)\n",
        "\n",
        "  op_qubit = len(transpiled.qubits)\n",
        "  op_depth = transpiled.depth()\n",
        "  op_width = transpiled.width()\n",
        "  op_cnot = transpiled.count_ops().get('cx', 0)\n",
        "  preparation_method  = 'UCG'\n",
        "\n",
        "  updateData(id=id,data=data, state=v, num_qubits=l[1], uniform=l[2], dense=l[3], sparsity=l[4],duration=duration,op_qubit=op_qubit, op_cnot=op_cnot, op_depth=op_depth, op_width=op_width, preparation_method=preparation_method)\n",
        "\n",
        "\n",
        "def bdsp(l,id):\n",
        "  global data\n",
        "  v = l[0]\n",
        "  before_time = datetime.now()\n",
        "  c = BdspInitialize(v).definition\n",
        "  transpiled = transpile(c, basis_gates=['u', 'cx'], optimization_level=0)\n",
        "  after_time = datetime.now()\n",
        "  duration = getDuration(before_time, after_time)\n",
        "  op_qubit = len(transpiled.qubits)\n",
        "  op_depth = transpiled.depth()\n",
        "  op_width = transpiled.width()\n",
        "  op_cnot = transpiled.count_ops().get('cx', 0)\n",
        "  preparation_method  = 'BDSP'\n",
        "\n",
        "  updateData(id=id,data=data, state=v, num_qubits=l[1], uniform=l[2], dense=l[3], sparsity=l[4],duration=duration,op_qubit=op_qubit, op_cnot=op_cnot, op_depth=op_depth, op_width=op_width, preparation_method=preparation_method)\n",
        "\n",
        "def dcsp(l,id):\n",
        "  global data\n",
        "  v = l[0]\n",
        "  before_time = datetime.now()\n",
        "  c = DcspInitialize(v).definition\n",
        "  transpiled = transpile(c, basis_gates=['u', 'cx'], optimization_level=0)\n",
        "  after_time = datetime.now()\n",
        "  duration = getDuration(before_time, after_time)\n",
        "  op_qubit = len(transpiled.qubits)\n",
        "  op_depth = transpiled.depth()\n",
        "  op_width = transpiled.width()\n",
        "  op_cnot = transpiled.count_ops().get('cx', 0)\n",
        "  preparation_method  = 'DCSP'\n",
        "\n",
        "  updateData(id=id,data=data, state=v, num_qubits=l[1], uniform=l[2], dense=l[3], sparsity=l[4],duration=duration,op_qubit=op_qubit, op_cnot=op_cnot, op_depth=op_depth, op_width=op_width, preparation_method=preparation_method)\n",
        "\n",
        "def multiplexor(l,id):\n",
        "  global data\n",
        "  v = l[0]\n",
        "  c = QuantumCircuit(l[1])\n",
        "  before_time = datetime.now()\n",
        "  c.initialize(v)\n",
        "  transpiled = transpile(c, basis_gates=['u', 'cx'], optimization_level=0)\n",
        "  after_time = datetime.now()\n",
        "  duration = getDuration(before_time, after_time)\n",
        "  op_qubit = len(transpiled.qubits)\n",
        "  op_depth = transpiled.depth()\n",
        "  op_width = transpiled.width()\n",
        "  op_cnot = transpiled.count_ops().get('cx', 0)\n",
        "  preparation_method  = 'Multiplexor'\n",
        "\n",
        "  updateData(id=id,data=data, state=v, num_qubits=l[1], uniform=l[2], dense=l[3], sparsity=l[4],duration=duration,op_qubit=op_qubit, op_cnot=op_cnot, op_depth=op_depth, op_width=op_width, preparation_method=preparation_method)\n",
        "\n",
        "\n",
        "def isometry(l,id):\n",
        "  global data\n",
        "  v = l[0]\n",
        "  before_time = datetime.now()\n",
        "  r = QuantumRegister(l[1])\n",
        "  c = QuantumCircuit(r)\n",
        "  c.isometry(v, q_input=[], q_ancillas_for_output=r)\n",
        "  transpiled = transpile(c, basis_gates=['u', 'cx'], optimization_level=0)\n",
        "\n",
        "  after_time = datetime.now()\n",
        "  duration = getDuration(before_time, after_time)\n",
        "  op_qubit = len(transpiled.qubits)\n",
        "  op_depth = transpiled.depth()\n",
        "  op_width = transpiled.width()\n",
        "  op_cnot = transpiled.count_ops().get('cx', 0)\n",
        "  preparation_method  = 'Isometry'\n",
        "\n",
        "  updateData(id=id,data=data, state=v, num_qubits=l[1], uniform=l[2], dense=l[3], sparsity=l[4],duration=duration,op_qubit=op_qubit, op_cnot=op_cnot, op_depth=op_depth, op_width=op_width, preparation_method=preparation_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb-ebkOje6U-"
      },
      "source": [
        "##Geração do Dataset\n",
        "\n",
        "Neste bloco de código, há funções da geração do ID junto com a lógica das funções que desenvolvem os estados e sua preparação, até incrementação no Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gF7bbClJ8fw9"
      },
      "outputs": [],
      "source": [
        "def generateIdentifier(tamanho=30):\n",
        "    caracteres = string.ascii_letters + string.digits\n",
        "    palavra_aleatoria = ''.join(random.choice(caracteres) for _ in range(tamanho))\n",
        "    return palavra_aleatoria\n",
        "\n",
        "def addBd(state, id):\n",
        "    try:\n",
        "      lowrank(state, id)\n",
        "    except Exception as e:\n",
        "      print(f\"Erro ao adicionar lowrank: {e}\")\n",
        "    try:\n",
        "      svd(state, id)\n",
        "    except Exception as e:\n",
        "      print(f\"Erro ao adicionar svd: {e}\")\n",
        "    try:\n",
        "      ucg(state, id)\n",
        "    except Exception as e:\n",
        "      print(f\"Erro ao adicionar ucg: {e}\")\n",
        "    try:\n",
        "      bdsp(state, id)\n",
        "    except Exception as e:\n",
        "      print(f\"Erro ao adicionar bdsp: {e}\")\n",
        "    try:\n",
        "      dcsp(state, id)\n",
        "    except Exception as e:\n",
        "      print(f\"Erro ao adicionar dcsp: {e}\")\n",
        "    try:\n",
        "      multiplexor(state, id)\n",
        "    except Exception as e:\n",
        "      print(f\"Erro ao adicionar multiplexor: {e}\")\n",
        "    try:\n",
        "      isometry(state, id)\n",
        "    except Exception as e:\n",
        "      print(f\"Erro ao adicionar isometry: {e}\")\n",
        "\n",
        "def createDenseUniformState(num_qubits):\n",
        "    state = denseUniformState(num_qubits)\n",
        "    id = generateIdentifier()\n",
        "    addBd(state, id)\n",
        "\n",
        "def createDenseNonUniformState(num_qubits):\n",
        "    state = denseNonUniformState(num_qubits)\n",
        "    id = generateIdentifier()\n",
        "    addBd(state, id)\n",
        "\n",
        "def createSparseUniformState(num_qubits, sparsity):\n",
        "    state = sparseUniformState(num_qubits, sparsity)\n",
        "    id = generateIdentifier()\n",
        "    addBd(state, id)\n",
        "\n",
        "def createSparseNonUniformState(num_qubits, sparsity):\n",
        "    state = sparseNonUniformState(num_qubits, sparsity)\n",
        "    id = generateIdentifier()\n",
        "    addBd(state, id)\n",
        "\n",
        "\n",
        "# Comentado cada preparação de estado quântico para criar csv separados.\n",
        "def generateStates(nqubits):\n",
        "  createDenseUniformState(nqubits)\n",
        "  #createDenseNonUniformState(nqubits)\n",
        "\n",
        "   #createSparseUniformState(nqubits,0.25)\n",
        "   #createSparseUniformState(nqubits,0.5)\n",
        "   #createSparseUniformState(nqubits,0.75)\n",
        "\n",
        "   #createSparseNonUniformState(nqubits,0.25)\n",
        "   #createSparseNonUniformState(nqubits,0.5)\n",
        "   #createSparseNonUniformState(nqubits,0.75)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yc7EN0bQTHS"
      },
      "source": [
        "##Incrementador para função de geração de estados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKH38cZ_Pe23"
      },
      "outputs": [],
      "source": [
        "nome_arquivo = \"DenseUniformState\"\n",
        "for _ in range(1,11):\n",
        "  print(_)\n",
        "  nQubits = 2\n",
        "  while nQubits < 13:\n",
        "    generateStates(nQubits)\n",
        "    addDF(data)\n",
        "    data = restartData(data)\n",
        "    nQubits+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75TsOwZ0Quc4"
      },
      "source": [
        "Salva o Dataset bruto em um arquivo csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdakEIGwQbyi"
      },
      "outputs": [],
      "source": [
        "df.to_csv(f'raw_{nome_arquivo}dataset.csv', index=False, sep=';')\n",
        "files.download(f'raw_{nome_arquivo}dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01ZkAc5XQ8EP"
      },
      "source": [
        "##Tratamento do Dataset\n",
        "\n",
        "O objetivo do tratamento é selecionar os melhores métodos por estado quântico com base no menor número de gates cnots no circuito e menor profundidade do circuito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC9V9Bu580DO"
      },
      "outputs": [],
      "source": [
        "# Supondo que você tenha um DataFrame chamado df\n",
        "# com as colunas mencionadas ('State', 'Qubit', 'Uniform State', 'Dense State', 'Sparsity', 'Output CNot Gate', 'Output Depth')\n",
        "\n",
        "# Ordenar o DataFrame pelos critérios em ordem\n",
        "#df_ordenado = df.sort_values(by=['Output CNot Gate', 'Output Depth'], ascending=[True, True]):\n",
        "#Esta linha ordena o DataFrame df com base nas colunas 'Output CNot Gate' e 'Output Depth'\n",
        "#em ordem ascendente. O resultado é atribuído a um novo DataFrame chamado df_ordenado.\n",
        "df_ordenado = df.sort_values(by=['Identifier','Output CNot Gate', 'Output Depth','Output Width'], ascending=[True, True, True, True])\n",
        "\n",
        "\n",
        "# Converter a coluna problemática em uma representação hashável\n",
        "#df_ordenado['State'] = df_ordenado['State'].apply(lambda x: tuple(x)): Aqui, a coluna 'State' do DataFrame df_ordenado é modificada.\n",
        "#A função apply é usada para aplicar uma função a cada elemento da coluna 'State'. Neste caso, a função lambda é usada para converter\n",
        "#cada valor da coluna 'State' em uma tupla. O resultado é atribuído de volta à coluna 'State' no DataFrame df_ordenado\n",
        "#df_ordenado['Identifier'] = df_ordenado['Identifier'].apply(lambda x: tuple(x))\n",
        "\n",
        "# Selecionar as melhores linhas\n",
        "#melhores_linhas = df_ordenado.groupby(['State', 'Qubit', 'Uniform State', 'Dense State', 'Sparsity']).head(1): Aqui, o DataFrame df_ordenado\n",
        "#é agrupado com base nas colunas 'State', 'Qubit', 'Uniform State', 'Dense State' e 'Sparsity'. A função groupby é utilizada para agrupar os dados\n",
        "#com base nessas colunas. Em seguida, a função head(1) é aplicada para cada grupo, mantendo apenas a primeira linha de cada grupo.\n",
        "#O resultado final é atribuído ao DataFrame melhores_linhas.\n",
        "\n",
        "#melhores_linhas = df_ordenado.groupby(['State', 'Qubit', 'Uniform State', 'Dense State', 'Sparsity']).head(1)\n",
        "melhores_linhas = df_ordenado.groupby(['Identifier']).head(1)\n",
        "#melhores_linhas = melhores_linhas.drop('State_str', axis=1)\n",
        "melhores_linhas = melhores_linhas.sort_values(by=['Qubit','Uniform State', 'Dense State', 'Sparsity'], ascending=[True,False, False, True])\n",
        "\n",
        "\n",
        "# Exibir o DataFrame resultante com todas as colunas\n",
        "#melhores_linhas.head(5): Finalmente, essa linha exibe as cinco primeiras linhas do DataFrame melhores_linhas, que contêm as primeiras linhas de cada grupo com base nas colunas mencionadas.\n",
        "#melhores_linhas.head(5)\n",
        "\n",
        "##Resumindo, o código ordena um DataFrame com base em duas colunas, converte uma coluna específica em tuplas, e depois mantém apenas a primeira linha de cada grupo com base em algumas colunas específicas. O resultado final é armazenado no DataFrame melhores_linhas e as cinco primeiras linhas desse DataFrame são exibidas.\n",
        "\n",
        "#melhores_linhas.describe()\n",
        "melhores_linhas.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPDP4tDs83sr"
      },
      "outputs": [],
      "source": [
        "melhores_linhas.to_csv(f'best_lines_{nome_arquivo}dataset.csv', index=False, sep=';')\n",
        "files.download(f'best_lines_{nome_arquivo}dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEozXRYRkqej"
      },
      "outputs": [],
      "source": [
        "df_ordenado.to_csv(f'ordenano_{nome_arquivo}dataset.csv', index=False, sep=';')\n",
        "files.download(f'ordenano_{nome_arquivo}dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6JjTyL986ZJ"
      },
      "outputs": [],
      "source": [
        "#melhores_linhas.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
